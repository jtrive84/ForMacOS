{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import tensorly\n",
    "\n",
    "lambda_ = np.asarray([39.288, 10.676])\n",
    "\n",
    "U1 = np.asarray([.5719, .1469, .5885, .9817, .5715, -.1210,]).reshape(3, -1)\n",
    "\n",
    "U2 = np.asarray([.5121, -.4042, .6284, .5877, .5856, .7009,]).reshape(3, -1)\n",
    "\n",
    "U3 = np.asarray([.5605, -.3179, .4921, -.3682, .6661, .8737,]).reshape(3, -1)\n",
    "\n",
    "U4 = np.asarray([.7502, -.9201, .6612, .3917,]).reshape(2, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of Xi: (3, 3, 3, 2)\n",
      "\n",
      "Xi_1,1\n",
      "[[4.83824 5.93702 5.53266]\n",
      " [4.97868 6.10935 5.69325]\n",
      " [4.83486 5.93287 5.52879]]\n",
      "\n",
      "Xi_1,2\n",
      "[[4.26426 5.23269 4.87629]\n",
      " [4.38803 5.38457 5.01783]\n",
      " [4.26127 5.22903 4.87288]]\n",
      "\n",
      "Xi_2,1\n",
      "[[4.24781 5.21251 4.85749]\n",
      " [4.37111 5.36381 4.99848]\n",
      " [4.24484 5.20886 4.85409]]\n",
      "\n",
      "Xi_2,2\n",
      "[[3.74387 4.59412 4.28122]\n",
      " [3.85254 4.72747 4.40548]\n",
      " [3.74125 4.59091 4.27822]]\n",
      "\n",
      "Xi_3,1\n",
      "[[5.74978 7.05558 6.57503]\n",
      " [5.91667 7.26038 6.76587]\n",
      " [5.74576 7.05064 6.57043]]\n",
      "\n",
      "Xi_3,2\n",
      "[[5.06766 6.21854 5.795  ]\n",
      " [5.21475 6.39904 5.9632 ]\n",
      " [5.06411 6.21419 5.79095]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "P1.I.b.i\n",
    "------\n",
    "Compute lambda_1 * U_1,1 outer_product U_2,1 outer_product U_3,1 outer_product U_4,1.\n",
    "\"\"\"\n",
    "lambda_1 = lambda_[0]\n",
    "u11 = U1[:,0]\n",
    "u21 = U2[:,0]\n",
    "u31 = U3[:,0]\n",
    "u41 = U4[:,0]\n",
    "\n",
    "Xi = np.zeros(u11.size * u21.size * u31.size * u41.size).reshape(\n",
    "    (u11.size, u21.size, u31.size, u41.size)\n",
    "    )\n",
    "\n",
    "for aa in range(len(u11)):\n",
    "    for bb in range(len(u21)):\n",
    "        for cc in range(len(u31)):\n",
    "            for dd in range(len(u41)):\n",
    "                Xi[aa, bb, cc, dd] = \\\n",
    "                    u11[aa] * u21[bb] * u31[cc] * u41[dd]\n",
    "                \n",
    "# Multiply each element of Xi by lambda_1.\n",
    "Xi*=lambda_1\n",
    "\n",
    "# Print dimensionality and contents of resulting tensor. \n",
    "print(\"Dimensionality of Xi: {}\".format(Xi.shape))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Xi_1,1\")\n",
    "print(Xi[:,:,0,0])\n",
    "\n",
    "print(\"\\nXi_1,2\")\n",
    "print(Xi[:,:,0,1])\n",
    "\n",
    "print(\"\\nXi_2,1\")\n",
    "print(Xi[:,:,1,0])\n",
    "\n",
    "print(\"\\nXi_2,2\")\n",
    "print(Xi[:,:,1,1])\n",
    "\n",
    "print(\"\\nXi_3,1\")\n",
    "print(Xi[:,:,2,0])\n",
    "\n",
    "print(\"\\nXi_3,2\")\n",
    "print(Xi[:,:,2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of Xii: (3, 3, 3, 2)\n",
      "\n",
      "Xii_1,1\n",
      "[[-0.18542  0.26959  0.32152]\n",
      " [-1.23911  1.80164  2.14867]\n",
      " [ 0.15273 -0.22206 -0.26484]]\n",
      "\n",
      "Xii_1,2\n",
      "[[ 0.07894 -0.11477 -0.13688]\n",
      " [ 0.52751 -0.76699 -0.91472]\n",
      " [-0.06502  0.09454  0.11274]]\n",
      "\n",
      "Xii_2,1\n",
      "[[-0.21476  0.31225  0.3724 ]\n",
      " [-1.43517  2.08671  2.48864]\n",
      " [ 0.17689 -0.2572  -0.30674]]\n",
      "\n",
      "Xii_2,2\n",
      "[[ 0.09142 -0.13293 -0.15853]\n",
      " [ 0.61097 -0.88834 -1.05945]\n",
      " [-0.07531  0.10949  0.13058]]\n",
      "\n",
      "Xii_3,1\n",
      "[[ 0.50959 -0.74094 -0.88366]\n",
      " [ 3.4055  -4.95154 -5.90528]\n",
      " [-0.41975  0.61031  0.72786]]\n",
      "\n",
      "Xii_3,2\n",
      "[[-0.21694  0.31543  0.37619]\n",
      " [-1.44977  2.10794  2.51397]\n",
      " [ 0.17869 -0.25982 -0.30986]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "P1.I.b.ii\n",
    "-------\n",
    "Compute lambda_2 * U_1,2 outer_product U_2,2 outer_product U_3,2 outer_product U_4,2.\n",
    "\"\"\"\n",
    "lambda_2 = lambda_[1]\n",
    "u12 = U1[:,1]\n",
    "u22 = U2[:,1]\n",
    "u32 = U3[:,1]\n",
    "u42 = U4[:,1]\n",
    "\n",
    "Xii = np.zeros(u12.size * u22.size * u32.size * u42.size).reshape(\n",
    "    (u12.size, u22.size, u32.size, u42.size)\n",
    "    )\n",
    "\n",
    "for aa in range(len(u12)):\n",
    "    for bb in range(len(u22)):\n",
    "        for cc in range(len(u32)):\n",
    "            for dd in range(len(u42)):\n",
    "                Xii[aa, bb, cc, dd] = \\\n",
    "                    u12[aa] * u22[bb] * u32[cc] * u42[dd]\n",
    "\n",
    "# Multiply each element of Xii by lambda_2.\n",
    "Xii*=lambda_2\n",
    "\n",
    "# Print dimensionality and slices of resulting tensor. \n",
    "print(\"Dimensionality of Xii: {}\".format(Xii.shape))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Xii_1,1\")\n",
    "print(Xii[:,:,0,0])\n",
    "\n",
    "print(\"\\nXii_1,2\")\n",
    "print(Xii[:,:,0,1])\n",
    "\n",
    "print(\"\\nXii_2,1\")\n",
    "print(Xii[:,:,1,0])\n",
    "\n",
    "print(\"\\nXii_2,2\")\n",
    "print(Xii[:,:,1,1])\n",
    "\n",
    "print(\"\\nXii_3,1\")\n",
    "print(Xii[:,:,2,0])\n",
    "\n",
    "print(\"\\nXii_3,2\")\n",
    "print(Xii[:,:,2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of Xcp: (3, 3, 3, 2)\n",
      "\n",
      "Xcp_1,1\n",
      "[[4.65282 6.20662 5.85418]\n",
      " [3.73957 7.911   7.84191]\n",
      " [4.98758 5.71081 5.26395]]\n",
      "\n",
      "Xcp_1,2\n",
      "[[4.34319 5.11792 4.73941]\n",
      " [4.91554 4.61758 4.10311]\n",
      " [4.19626 5.32356 4.98562]]\n",
      "\n",
      "Xcp_2,1\n",
      "[[4.03306 5.52476 5.22988]\n",
      " [2.93594 7.45051 7.48712]\n",
      " [4.42173 4.95166 4.54735]]\n",
      "\n",
      "Xcp_2,2\n",
      "[[3.8353  4.46119 4.12268]\n",
      " [4.46351 3.83913 3.34603]\n",
      " [3.66595 4.7004  4.40881]]\n",
      "\n",
      "Xcp_3,1\n",
      "[[6.25937 6.31464 5.69137]\n",
      " [9.32218 2.30883 0.86059]\n",
      " [5.32601 7.66095 7.29829]]\n",
      "\n",
      "Xcp_3,2\n",
      "[[4.85071 6.53397 6.17118]\n",
      " [3.76498 8.50698 8.47717]\n",
      " [5.2428  5.95438 5.48109]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "P1.I.b.iii\n",
    "--------\n",
    "Calculate the full reconstruction.\n",
    "\"\"\"\n",
    "# The full reconstruction would be the aggregation of the results from \n",
    "# P1.b.i & P1.b.ii. Thus the full reconstruction is given by:\n",
    "Xcp = Xi + Xii\n",
    "\n",
    "# Print dimensionality and slices of resulting tensor. \n",
    "print(\"Dimensionality of Xcp: {}\".format(Xpc.shape))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Xcp_1,1\")\n",
    "print(Xcp[:,:,0,0])\n",
    "\n",
    "print(\"\\nXcp_1,2\")\n",
    "print(Xcp[:,:,0,1])\n",
    "\n",
    "print(\"\\nXcp_2,1\")\n",
    "print(Xcp[:,:,1,0])\n",
    "\n",
    "print(\"\\nXcp_2,2\")\n",
    "print(Xcp[:,:,1,1])\n",
    "\n",
    "print(\"\\nXcp_3,1\")\n",
    "print(Xcp[:,:,2,0])\n",
    "\n",
    "print(\"\\nXcp_3,2\")\n",
    "print(Xcp[:,:,2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reconstructed tensor: (3, 3, 3, 2)\n",
      "\n",
      "Xtucker_1,1\n",
      "[[2.99861 5.69567 5.83211]\n",
      " [1.29308 6.30948 7.21663]\n",
      " [8.16975 4.9483  2.99313]]\n",
      "\n",
      "Xtucker_1,2\n",
      "[[5.3689  5.70916 4.96526]\n",
      " [5.98013 6.08205 5.19245]\n",
      " [4.57487 5.62486 5.1583 ]]\n",
      "\n",
      "Xtucker_2,1\n",
      "[[ 1.81741  4.70075  5.05835]\n",
      " [-0.19876  5.42224  6.69002]\n",
      " [ 7.64646  3.49445  1.41422]]\n",
      "\n",
      "Xtucker_2,2\n",
      "[[5.68431 5.08491 4.08604]\n",
      " [6.6348  5.31253 4.00956]\n",
      " [4.01155 5.29641 4.96748]]\n",
      "\n",
      "Xtucker_3,1\n",
      "[[6.4876  7.33725 6.53488]\n",
      " [6.72026 7.26994 6.36605]\n",
      " [6.9159  8.72803 8.07223]]\n",
      "\n",
      "Xtucker_3,2\n",
      "[[1.91262 5.86532 6.44382]\n",
      " [0.91922 6.66557 7.79044]\n",
      " [4.95192 4.63444 3.80933]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "P1.II\n",
    "--------\n",
    "Compute the reconstruction of the Tucker decomposition.\n",
    "\"\"\"\n",
    "from tensorly import tucker_tensor\n",
    "\n",
    "G11 = np.asarray([38.946, 0.8653, .9666, -4.8832]).reshape(2, 2)\n",
    "\n",
    "G21 = np.asarray([-0.4799, -0.0792, -1.7302, -4.3675]).reshape(2, 2)\n",
    "\n",
    "G12 = np.asarray([0.7059, -1.6496, 0.7553, -1.1648]).reshape(2, 2)\n",
    "\n",
    "G22 = np.asarray([5.7493, -3.3204, -2.0019, 7.6587 ]).reshape(2, 2)\n",
    "\n",
    "U1 = np.asarray([0.5661, -0.1945, 0.6005, -0.5685, 0.5648, 0.7994]).reshape(3, 2)\n",
    "\n",
    "U2 = np.asarray([0.5031, 0.8331, 0.6345, -0.1755, 0.5867, -0.5246]).reshape(3, 2)\n",
    "\n",
    "U3 = np.asarray([0.5773, -0.3364, 0.5013, -0.5733, 0.6445, 0.7471]).reshape(3, 2)\n",
    "\n",
    "U4 = np.asarray([0.7524, -0.6587, 0.6587, 0.7524]).reshape(2, 2)\n",
    "\n",
    "# Bind reference to core tensor G.\n",
    "G = np.asarray([G11, G21, G12, G22]).reshape(2, 2, 2, 2)\n",
    "\n",
    "Xtucker = tucker_tensor.tucker_to_tensor((G, [U1, U2, U3, U4]))\n",
    "\n",
    "print(\"Shape of reconstructed tensor: {}\".format(Xtucker.shape))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Xtucker_1,1\")\n",
    "print(Xtucker[:,:,0,0])\n",
    "\n",
    "print(\"\\nXtucker_1,2\")\n",
    "print(Xtucker[:,:,0,1])\n",
    "\n",
    "print(\"\\nXtucker_2,1\")\n",
    "print(Xtucker[:,:,1,0])\n",
    "\n",
    "print(\"\\nXtucker_2,2\")\n",
    "print(Xtucker[:,:,1,1])\n",
    "\n",
    "print(\"\\nXtucker_3,1\")\n",
    "print(Xtucker[:,:,2,0])\n",
    "\n",
    "print(\"\\nXtucker_3,2\")\n",
    "print(Xtucker[:,:,2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "P1.III\n",
    "--------\n",
    "Calculate the MSE for both the CP and Tucker decompositions. Briefly discuss \n",
    "(2-3 sentences should be sufficient) the difference, especially regarding the \n",
    "relative reduction of features for each method.\n",
    "\"\"\"\n",
    "X11 = np.asarray([4., 0., 9., 7., 9., 9., 4., 8., 5.,]).reshape(3, 3)\n",
    "\n",
    "X21 = np.asarray([7., 8., 2., 1., 5., 8., 7., 9., 2.,]).reshape(3, 3)\n",
    "\n",
    "X31 = np.asarray([7., 9., 4., 10., 1., 2., 1., 5., 8.,]).reshape(3, 3)\n",
    "\n",
    "X12 = np.asarray([6., 5., 1., 3., 3., 5., 1., 8., 7.,]).reshape(3, 3)\n",
    "\n",
    "X22 = np.asarray([8., 2., 3., 4., 3., 3., 2., 4., 6.,]).reshape(3, 3)\n",
    "\n",
    "X32 = np.asarray([6., 6., 8., 5., 9., 8., 3., 9., 5.,]).reshape(3, 3)\n",
    "\n",
    "\n",
    "# Populate Xactual with provided frontal slices.\n",
    "Xactual = np.zeros(3 * 3 * 3 * 2).reshape(3, 3, 3, 2)\n",
    "Xactual[:, :, 0, 0] = X11\n",
    "Xactual[:, :, 1, 0] = X21\n",
    "Xactual[:, :, 2, 0] = X31\n",
    "Xactual[:, :, 0, 1] = X12\n",
    "Xactual[:, :, 1, 1] = X22\n",
    "Xactual[:, :, 2, 1] = X32\n",
    "\n",
    "\n",
    "# Compute MSE of Xcp.\n",
    "MSEcp = np.power((Xactual - Xcp).ravel(), 2).sum() / Xactual.size\n",
    "MSEtuc\n",
    "ker = np.power((Xactual - Xtucker).ravel(), 2).sum() / Xactual.size\n",
    "\n",
    "print(\"MSE CP    : {:.2f}\".format(MSEcp))\n",
    "print(\"MSE Tucker: {:.2f}\".format(MSEtucker))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xactual.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute outer product of two vectors:\n",
    "\n",
    "# U1[:,0].reshape(3, 1) *  U2[:,0].reshape(1, 3)\n",
    "\n",
    "# np.outer(U1[:,0], U2[:,0])\n",
    "\n",
    "\n",
    "# ðœ†1ð‘ˆ1,1 âˆ˜ ð‘ˆ2,1 âˆ˜ ð‘ˆ3,1 âˆ˜ ð‘ˆ4,1\n",
    "\n",
    "\n",
    "\n",
    "# NumPy ufuncs, such as multiply, have an outer method that almost does what you want. The following:\n",
    "temp = numpy.multiply.outer(A, B)\n",
    "C = numpy.swapaxes(temp, 1, 2)\n",
    "\n",
    "# produces a result such that temp[a, b, c, d] == A[a, b] * B[c, d]. \n",
    "# You want C[a, b, c, d] == A[a, c] * B[b, d]. The swapaxes call \n",
    "# rearranges temp to put it in the order you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einsum does not allow broadcasting by default\n",
    "\n",
    "\n",
    "Whenever a label is repeated it is summed, so np.einsum('i,i', a, b) is equivalent to np.inner(a,b).\n",
    "\n",
    "\n",
    "If a label appears only once, it is not summed, so np.einsum('i', a) produces a view of a with no changes.\n",
    "\n",
    "\n",
    "np.einsum('ij,jk', a, b) describes traditional matrix multiplication and is equivalent to np.matmul(a,b).\n",
    "\n",
    "\n",
    "Repeated subscript labels in one operand take the diagonal. For example, np.einsum('ii', a) is equivalent to np.trace(a).\n",
    "\n",
    "\n",
    "np.einsum('ij', a) doesnâ€™t affect a 2D array, while np.einsum('ji', a) takes its transpose\n",
    "\n",
    "\n",
    "np.einsum('ij,jk', a, b) returns a matrix multiplication, while, np.einsum('ij,jh', a, b) returns the transpose of the multiplication since subscript â€˜hâ€™ precedes subscript â€˜iâ€™.\n",
    "\n",
    "\n",
    "np.einsum('i->', a) is like np.sum(a, axis=-1), and np.einsum('ii->i', a) is like np.diag(a).\n",
    "\n",
    "\n",
    "np.einsum('ij,jh->ih', a, b) directly specifies the order of the output subscript labels and therefore returns matrix multiplication, unlike the example above in implicit mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "d = 10 \n",
    "U = np.random.rand(d) \n",
    "V = np.random.rand(d) \n",
    "T = np.random.rand(d) \n",
    "R = np.einsum('ai,aj,ak->ijk',U,V,T)\n",
    "\n",
    "R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U1[:,0].reshape(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U1[:,0].reshape(3, 1) *  U2[:,0].reshape(1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.outer(U1[:,0], U2[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If G is of shape (2,2,2,2), then G o U_1 is of shape (3,2,2,2).\n",
    "\n",
    "then G o U_1 o U_2 is of shape (3,3,2,2)\n",
    "\n",
    "then G o U_1 o U_2 o U_3 is of shape (3,3,3,2)\n",
    "\n",
    "and lastly G o U_1 o U_2 o U_3 o U_4 is of shape (3,3,3,2) which is the reconstruction matrix\n",
    "\n",
    "Is my understanding correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "\n",
    "U_1,1 corresponds to the first U matrix (U_1) and the first column of that matrix?\n",
    "\n",
    "In our example, that would be [.5719, .5885, .5715]?\n",
    "\n",
    "Then, in part three, we have entire matrices denoted by X_1,1 which to me would be an individual element of a matrix (1=the row, and 1=the column).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from numpy import linalg as LA\n",
    "\n",
    "prng = np.random.RandomState(516)\n",
    "\n",
    "a = prng.randn(25).reshape(5, -1)\n",
    "n0 = LA.norm(a[:,0])\n",
    "n1 = distance.euclidean(a[:,0], np.zeros(a.shape[0]))\n",
    "\n",
    "print(\"n0: {}\".format(n0))\n",
    "print(\"n1: {}\".format(n1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [5, 6, 7, 8]\n",
    "c = np.outer(b, a)\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
