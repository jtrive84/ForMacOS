{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud, Waste and Abuse Classifier Walkthrough\n",
    "\n",
    "\n",
    "Anomaly detection typically deals with highly imbalanced datasets. There are a few ways to address this imbalance. One approach is to upsampling the minority class using the SMOTE algorithm to generate synthetic minority samples (see 1st link).\n",
    "\n",
    "\n",
    "\n",
    "### Relevant Links:\n",
    "\n",
    "1. http://www.jmlr.org/papers/volume18/16-365/16-365.pdf\n",
    "2. https://scikit-learn.org/stable/modules/ensemble.html#adaboost\n",
    "3. https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "4. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows is the source code comprising the FWA classifier. The codebase is maintained under version control, a working copy of which can be checkout by running the following command (requires that Git be installed, which can be downloaded [here](https://git-scm.com/downloads)):\n",
    "\n",
    "```\n",
    "$ git clone file:///s/GLTCVAL.W/Repos/FWA.git\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in FWA training dataset. Update PATH variable to point\n",
    "to local working copy's `TRAINING.csv`.\n",
    "\"\"\"\n",
    "import datetime\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "import importlib.util\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import  Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, AdaBoostClassifier, VotingClassifier,\n",
    "    GradientBoostingClassifier, ExtraTreesClassifier\n",
    "    )\n",
    "pd.options.mode.chained_assignment = None # \"warn\"\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 500)\n",
    "np.set_printoptions(\n",
    "    edgeitems=5, linewidth=200, suppress=True, nanstr='NaN',\n",
    "    infstr='Inf', precision=5\n",
    "    )\n",
    "\n",
    "CSV_PATH = \"C:\\\\Users\\\\cac9159\\\\Repos\\\\LTC\\\\FWA\\\\Datasets\\\\TRAINING.csv\"\n",
    "dfinit = pd.read_csv(DATA_PATH, sep=\",\", error_bad_lines=False)\n",
    "\n",
    "keycols   = [\"CLAIM_NUMBER\", \"POLICY_NUMBER\", \"RESIDENT_STATE\", \"FRAUD_INDICATOR\"]\n",
    "cont_vars = [\"PAID_AMOUNT\", \"DLR_AMT\"]\n",
    "cat_vars  = [\"ATTAINED_AGE_BANDED\", \"BENEFIT_PERIOD\", \"BENEFIT_TRIGGER_OPTIONS\", \"COLI\", \n",
    "             \"DAILY_BENEFIT_INFL_BANDED\", \"DUAL_WAIVER\", \"INDEMNITY_VS_EXPENSE_INCURRED\", \n",
    "             \"LINKED_POLICY_INDICATOR\", \"MAX_REPEATED_CALLS\", \"PREMIUM_PAYMENT_MODE\", \n",
    "             \"PREMIUM_WAIVED\", \"RESTORATION_OF_BENEFITS\", \"SITUS_CURRENT\", \n",
    "             \"TAX_QUALIFIED_STATUS\", \"UNDERWRITING_CLASS\", \"ELIM_PERIOD_BANDED\",]\n",
    "\n",
    "df = dfinit[keycols + cont_vars + cat_vars]\n",
    "nrows, ncols = df.shape[0], df.shape[1]\n",
    "\n",
    "\n",
    "# Assign unique identifier to each record in sample cohort.\n",
    "df[\"ID\"] = dforiginal[\"POLICY_NUMBER\"].astype(str) + \"-\" + dforiginal[\"CLAIM_NUMBER\"].astype(str)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "df[\"FRAUD_INDICATOR\"] = lb.fit_transform(df[\"FRAUD_INDICATOR\"])\n",
    "\n",
    "dffeatures = df.drop(labels=[\"ID\", \"FRAUD_INDICATOR\"], axis=1)\n",
    "response = df[\"FRAUD_INDICATOR\"]\n",
    "datindex = df[\"ID\"]\n",
    "\n",
    "\n",
    "# Separate training features from response; partition training and test data.\n",
    "Xtrain, Xtest, ytrain, ytest, indxtrain, indxtest = \\\n",
    "    train_test_split(\n",
    "        dffeatures, response, datindex, test_size=.25,\n",
    "        random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "\n",
    "# Impute missing categorical or continuous values ============================]\n",
    "catimp  = SimpleImputer(missing_values=MISSING_CAT_STR, strategy=IMPUTE_STRATEGY)\n",
    "contimp = SimpleImputer(missing_values=np.NaN, strategy=IMPUTE_STRATEGY)\n",
    "dfcont, dfcat = Xtrain[cont_vars], Xtrain[cat_vars]\n",
    "\n",
    "dfcontimp = contimp.fit_transform(dfcont)\n",
    "dfcatimp  = catimp.fit_transform(dfcat)\n",
    "\n",
    "\n",
    "# Scale continuous features to eliminate magnitude bias ======================]\n",
    "# Standardization of a dataset is a common requirement for many machine\n",
    "# learning estimators: they might behave badly if the individual features\n",
    "# do not more or less look like standard normally distributed data.\n",
    "std_scaler  = StandardScaler()\n",
    "cont_df_scl = pd.DataFrame(\n",
    "    std_scaler.fit_transform(dfcontimp), columns=dfcont.columns\n",
    "    )\n",
    "\n",
    "# One-hot encode categorical features.\n",
    "cat_df_enc = pd.get_dummies(\n",
    "    pd.DataFrame(dfcatimp, columns=dfcat.columns), drop_first=True\n",
    "    )\n",
    "\n",
    "Xtrain = pd.concat([cont_df_scl, cat_df_enc], axis=1)\n",
    "\n",
    "# Transform test data using same objects from training data ==================]\n",
    "# NOTE: Call only `transform` on test dataset.\n",
    "_cont_df2, _cat_df2 = Xtest[cont_vars], Xtest[cat_vars]\n",
    "cont_df_imp2 = contimp.transform(_cont_df2)\n",
    "cat_df_imp2  = catimp.transform(_cat_df2)\n",
    "\n",
    "# Scale continuous features to eliminate magnitude bias.\n",
    "cont_df_scl2 = pd.DataFrame(\n",
    "    std_scaler.transform(cont_df_imp2), columns=dfcont.columns\n",
    "    )\n",
    "\n",
    "# One-hot encode categorical features.\n",
    "cat_df_enc2 = pd.get_dummies(\n",
    "    pd.DataFrame(cat_df_imp2, columns=dfcat.columns), drop_first=True\n",
    "    )\n",
    "\n",
    "Xtest = pd.concat([cont_df_scl2, cat_df_enc2], axis=1)\n",
    "\n",
    "\n",
    "##### Modeling ################################################################\n",
    "\n",
    "scoring_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1_micro\", \"f1_macro\", \"roc_auc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression Classifier ==============================================]\n",
    "# Initialize default LogisticRegression model. Then perform grid search\n",
    "# to identify optimal parameters w.r.t. \"recall\".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model0 = LogisticRegression()\n",
    "\n",
    "param_grid = [{\n",
    "    \"fit_intercept\":[True, False],\n",
    "    \"solver\"       :[\"newton-cg\", \"lbfgs\", \"saga\"],\n",
    "    \"C\"            :[1/10000, 1/1000, 1/100, 1/10, 1, 10, 100, 1000, 10000],\n",
    "    }]\n",
    "\n",
    "\n",
    "# Evaluate performance of optimal model on test data.\n",
    "grid_search = GridSearchCV(model0, param_grid, cv=5, scoring=scoring_metrics[2], verbose=0)\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "bestparams0 = grid_search.best_params_\n",
    "bestmodel0  = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Apply bestmodel0 to out-of-sample test data `Xtest`.\n",
    "# model0_pred = bestmodel0.predict(Xtest)\n",
    "# model0_prob = bestmodel0.predict_proba(Xtest)\n",
    "\n",
    "\n",
    "# # Asses performance of model0.\n",
    "# print(\"Accuracy : {}\".format(metrics.accuracy_score(ytest, model0_pred)))\n",
    "# print(\"Precision: {}\".format(metrics.precision_score(ytest, model0_pred, average=\"weighted\")))\n",
    "# print(\"Recall   : {}\".format(metrics.recall_score(ytest, model0_pred, average=\"weighted\")))\n",
    "# print(\"f1-score : {}\".format(metrics.f1_score(ytest, model0_pred, average=\"weighted\")))\n",
    "# print(\"ROC-AUC  : {}\".format(metrics.roc_auc_score(ytest, model0_pred))\n",
    "# print(confusion_matrix(ytest, model0_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = Xtrain.iloc[1000:2555,:]\n",
    "ytest = ytrain[1000:2555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1555, 55)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9890675241157556\n",
      "Precision: 0.9891872741737661\n",
      "Recall   : 0.9890675241157556\n",
      "f1-score : 0.9850573636683075\n",
      "ROC-AUC  : 0.575\n",
      "[[1535    0]\n",
      " [  17    3]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of optimal model on test data.\n",
    "# grid_search = GridSearchCV(model0, param_grid, cv=5, scoring=scoring_metrics[2], verbose=0)\n",
    "# grid_search.fit(Xtrain, ytrain)\n",
    "# bestparams0 = grid_search.best_params_\n",
    "# bestmodel0  = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Apply bestmodel0 to out-of-sample test data `Xtest`.\n",
    "model0_pred = bestmodel0.predict(Xtest)\n",
    "model0_prob = bestmodel0.predict_proba(Xtest)\n",
    "\n",
    "\n",
    "# # Asses performance of model0.\n",
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(ytest, model0_pred)))\n",
    "print(\"Precision: {}\".format(metrics.precision_score(ytest, model0_pred, average=\"weighted\")))\n",
    "print(\"Recall   : {}\".format(metrics.recall_score(ytest, model0_pred, average=\"weighted\")))\n",
    "print(\"f1-score : {}\".format(metrics.f1_score(ytest, model0_pred, average=\"weighted\")))\n",
    "print(\"ROC-AUC  : {}\".format(metrics.roc_auc_score(ytest, model0_pred)))\n",
    "print(confusion_matrix(ytest, model0_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest Classifier ====================================================]\n",
    "model1 = RandomForestClassifier()\n",
    "\n",
    "\n",
    "param_grid = [{\n",
    "    \"n_estimators\":[10, 25, 50, 75, 100, 150, 200, 250, 500],\n",
    "    \"max_depth\"   :[None, 2, 5, 10, 15],\n",
    "    \"criterion\"   :[\"gini\", \"entropy\"],\n",
    "    \"bootstrap\"   :[True, False],\n",
    "    \"warm_start\"  :[True, False],\n",
    "    }]\n",
    "\n",
    "\n",
    "# Evaluate performance of optimal model on test data.\n",
    "grid_search = GridSearchCV(model1, param_grid, cv=5, scoring=scoring_metrics[2], verbose=1)\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "bestparams1 = grid_search.best_params_\n",
    "bestmodel1  = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Apply bestmodel0 to out-of-sample test data `Xtest`.\n",
    "model1_pred = bestmodel1.predict(Xtest)\n",
    "model1_prob = bestmodel1.predict_proba(Xtest)\n",
    "\n",
    "\n",
    "# Asses performance of model1.\n",
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(ytest, model1_pred)))\n",
    "print(\"Precision: {}\".format(metrics.precision_score(ytest, model1_pred, average=\"weighted\")))\n",
    "print(\"Recall   : {}\".format(metrics.recall_score(ytest, model1_pred, average=\"weighted\")))\n",
    "print(\"f1-score : {}\".format(metrics.f1_score(ytest, model1_pred, average=\"weighted\")))\n",
    "print(\"ROC-AUC  : {}\".format(metrics.roc_auc_score(ytest, model1_pred))\n",
    "print(confusion_matrix(ytest, model1_pred))\n",
    "\n",
    "# Difference between RandomForestClassifier and ExtraTreesClassifier:\n",
    "# ExtraTreesClassifier always tests random splits over fraction of features.\n",
    "# RandomForestClassifier tests all possible splits over fraction of features.\n",
    "\n",
    "\n",
    "# RandomForestClassifier can produce feature importances.\n",
    "importances  = bestmodel1.feature_importances_\n",
    "stddev       = np.std([tree.feature_importances_ for tree in bestmodel1.estimators_], ddof=1)\n",
    "feature_indx = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"model1 feature ranking: \")\n",
    "for f in range(Xtrain.shape[1]):\n",
    "    print(\"{}. feature {} ({})\".format(f + 1, feature_indx[f], importances[feature_indx[f]]))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(Xtrain.shape[1]), importances[feature_indx], color=\"r\",\n",
    "        yerr=stddev[feature_indx], align=\"center\")\n",
    "plt.xlim([-1, Xtrain.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# AdaBoost Classifier ========================================================]\n",
    "model2 = AdaBoostClassifier()\n",
    "\n",
    "\n",
    "param_grid = [{\n",
    "    \"algorithm\"    :[\"SAMME\", \"SAMME.R\"],\n",
    "    \"n_estimators\" :[10, 50, 100, 150, 200],\n",
    "    \"learning_rate\":[.50, 1.0, 1.5],\n",
    "    }]\n",
    "\n",
    "\n",
    "# Evaluate performance of optimal model on test data.\n",
    "grid_search = GridSearchCV(model2, param_grid, cv=5, scoring=scoring_metrics[2], verbose=1)\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "bestparams1 = grid_search.best_params_\n",
    "bestmodel2  = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Apply bestmodel2 to out-of-sample test data `Xtest`.\n",
    "model2_pred = bestmodel2.predict(Xtest)\n",
    "model2_prob = bestmodel2.predict_proba(Xtest)\n",
    "\n",
    "\n",
    "# Asses performance of model2.\n",
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(ytest, model2_pred)))\n",
    "print(\"Precision: {}\".format(metrics.precision_score(ytest, model2_pred, average=\"weighted\")))\n",
    "print(\"Recall   : {}\".format(metrics.recall_score(ytest, model2_pred, average=\"weighted\")))\n",
    "print(\"f1-score : {}\".format(metrics.f1_score(ytest, model2_pred, average=\"weighted\")))\n",
    "print(\"ROC-AUC  : {}\".format(metrics.roc_auc_score(ytest, model2_pred))\n",
    "print(confusion_matrix(ytest, model2_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Multi-Layer Perceptron Classifier ==========================================]\n",
    "model3 = MLPClassifier()\n",
    "\n",
    "param_grid = [{\n",
    "    \"activation\":[\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\"    :[\"lbgfs\", \"sgd\", \"adam\"],\n",
    "    \"warm_start\":[True, False],\n",
    "    \"momentum\"  :[.1, .25, .50, .75, .9, .99],\n",
    "    }]\n",
    "\n",
    "# Evaluate performance of optimal model on test data.\n",
    "grid_search = GridSearchCV(model3, param_grid, cv=5, scoring=scoring_metrics[2], verbose=1)\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "bestparams1 = grid_search.best_params_\n",
    "bestmodel3  = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Apply bestmodel3 to out-of-sample test data `Xtest`.\n",
    "model3_pred = bestmodel3.predict(Xtest)\n",
    "model3_prob = bestmodel3.predict_proba(Xtest)\n",
    "\n",
    "\n",
    "# Asses performance of model3.\n",
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(ytest, model3_pred)))\n",
    "print(\"Precision: {}\".format(metrics.precision_score(ytest, model3_pred, average=\"weighted\")))\n",
    "print(\"Recall   : {}\".format(metrics.recall_score(ytest, model3_pred, average=\"weighted\")))\n",
    "print(\"f1-score : {}\".format(metrics.f1_score(ytest, model3_pred, average=\"weighted\")))\n",
    "print(\"ROC-AUC  : {}\".format(metrics.roc_auc_score(ytest, model3_pred))\n",
    "print(confusion_matrix(ytest, model3_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Gradient Boosting Classifier ===============================================]\n",
    "model4 = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = [{\n",
    "    \"loss\"        :[\"deviance\", \"exponential\"],\n",
    "    \"n_estimators\":[50, 100, 250, 500, 1000],\n",
    "    \"subsample\"   :[.01, .25, .50, .75, .99, 1.0],\n",
    "    \"warm_start\"  :[True, False],\n",
    "    }]\n",
    "\n",
    "# Evaluate performance of optimal model on test data.\n",
    "grid_search = GridSearchCV(model4, param_grid, cv=5, scoring=scoring_metrics[2], verbose=1)\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "bestparams1 = grid_search.best_params_\n",
    "bestmodel4  = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Apply bestmodel4 to out-of-sample test data `Xtest`.\n",
    "model4_pred = bestmodel4.predict(Xtest)\n",
    "model4_prob = bestmodel4.predict_proba(Xtest)\n",
    "\n",
    "\n",
    "# Asses performance of model4.\n",
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(ytest, model4_pred)))\n",
    "print(\"Precision: {}\".format(metrics.precision_score(ytest, model4_pred, average=\"weighted\")))\n",
    "print(\"Recall   : {}\".format(metrics.recall_score(ytest, model4_pred, average=\"weighted\")))\n",
    "print(\"f1-score : {}\".format(metrics.f1_score(ytest, model4_pred, average=\"weighted\")))\n",
    "print(\"ROC-AUC  : {}\".format(metrics.roc_auc_score(ytest, model4_pred))\n",
    "print(confusion_matrix(ytest, model4_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Final classification with VotingClassifier =================================]\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[(\"lr\", bestmodel0), (\"rf\", bestmodel1), (\"ada\", bestmodel2),\n",
    "                (\"mlp\", bestmodel3), (\"gb\", bestmodel4)],\n",
    "    voting=\"hard\",\n",
    "    )\n",
    "\n",
    "voting_model_pred = voting_model.predict(Xtest)\n",
    "voting_model_prob = voting_model.predict_proba(Xtest)\n",
    "\n",
    "\n",
    "# Asses performance of voting_model.\n",
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(ytest, voting_model_pred)))\n",
    "print(\"Precision: {}\".format(metrics.precision_score(ytest, voting_model_pred, average=\"weighted\")))\n",
    "print(\"Recall   : {}\".format(metrics.recall_score(ytest, voting_model_pred, average=\"weighted\")))\n",
    "print(\"f1-score : {}\".format(metrics.f1_score(ytest, voting_model_pred, average=\"weighted\")))\n",
    "print(\"ROC-AUC  : {}\".format(metrics.roc_auc_score(ytest, voting_model_pred))\n",
    "print(confusion_matrix(ytest, voting_model_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
