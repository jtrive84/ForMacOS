{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Classifier Threshold in scikit-learn\n",
    "\n",
    "\n",
    "The discrimination threshold cannot be updated for scikit-learn classifiers.\n",
    "However, it is possible to access the decision scores which are used to assign class labels to observations. \n",
    "Decision scores can be obtained by calling the classifier's `decision_function` method, which returns\n",
    "a score for each observation. The decisions scores can then be used to update model predictions based on the\n",
    "desired criteria. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 500)\n",
    "np.set_printoptions(\n",
    "    edgeitems=5, linewidth=200, suppress=True, nanstr='NaN',\n",
    "    infstr='Inf', precision=5\n",
    "    )\n",
    "\n",
    "RANDOM_STATE = 516\n",
    "TRAIN_SIZE   = .70\n",
    "TEST_SIZE    = 1 - TRAIN_SIZE\n",
    "ID           = \"id\"\n",
    "\n",
    "# fpath = \"S:\\\\public\\\\Actuarial\\\\DSSG\\\\20170721_Materials\\\\mw.data\"\n",
    "# hdrs  = [\"ID\", \"GENDER\", \"HEIGHT\", \"HAND_LENGTH\", \"FOREARM_LENGTH\"]\n",
    "# df    = pd.read_table(fpath, sep=\"\\s+\", names=hdrs)\n",
    "\n",
    "\n",
    "data_path = \"https://gist.githubusercontent.com/jtrive84/c1e23acb2624733ada178260cc3c683c/raw/3cf7e81263de12727ac4d6b7391bf6766f942f2b/admissions.csv\"\n",
    "\n",
    "dfall = pd.read_csv(data_path)\n",
    "\n",
    "\n",
    "categorical_vars = [\"rank\"]\n",
    "continuous_vars  = [\"gre\", \"gpa\",]\n",
    "response         = \"admit\"\n",
    "\n",
    "\n",
    "# Split data into train, validation and test cohorts. \n",
    "dftrain, dftest0, ytrain, ytest0 = \\\n",
    "    train_test_split(\n",
    "        dfall[categorical_vars + continuous_vars], \n",
    "        dfall[response], test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "# Split dftest0 into validation and test cohorts.\n",
    "dfvalidate, dftest, yvalidate, ytest = \\\n",
    "    train_test_split(\n",
    "        dftest0, ytest0, test_size=.30, random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "\n",
    "# Recombine dftrain + ytrain, dfvalidate + yvalidate and dftest + ytest.\n",
    "dftrain = dftrain.join(ytrain).reset_index(drop=True)\n",
    "dfvalidate = dfvalidate.join(yvalidate).reset_index(drop=True)\n",
    "dftest = dftest.join(ytest).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# Transform training data using same objects from training data. Note that we call   |\n",
    "# only `transform` on test dataset (not fit_transform).                              |\n",
    "# ------------------------------------------------------------------------------------\n",
    "dfcategorical_train = dftrain[categorical_vars]\n",
    "dfcontinuous_train = dftrain[continuous_vars]\n",
    "\n",
    "categorical_imputer = SimpleImputer(missing_values=np.NaN, strategy=\"most_frequent\")\n",
    "continuous_imputer = SimpleImputer(missing_values=np.NaN, strategy=\"median\")\n",
    "\n",
    "train_categorical_arr = categorical_imputer.fit_transform(dfcategorical_train[categorical_vars])\n",
    "train_continuous_arr = continuous_imputer.fit_transform(dfcontinuous_train[continuous_vars])\n",
    "\n",
    "# One-hot encode categorical features.\n",
    "dfcategorical_train = pd.DataFrame(\n",
    "    train_categorical_arr, columns=categorical_vars\n",
    "    )\n",
    "\n",
    "dfcategorical_train = pd.get_dummies(\n",
    "    dfcategorical_train, columns=categorical_vars, drop_first=True\n",
    "    )\n",
    "\n",
    "# Scale continuous features to eliminate magnitude bias.\n",
    "std_scaler = StandardScaler()\n",
    "dfcontinuous_train = pd.DataFrame(\n",
    "    std_scaler.fit_transform(train_continuous_arr), columns=dfcontinuous_train.columns\n",
    "    )\n",
    "\n",
    "# Recombine dfcategorical and dfcontinuous into single DataFrame with index.\n",
    "dftrain = pd.concat(\n",
    "    [dftrain[[\"id\"]], dfcategorical_train, dfcontinuous_train, dftrain[[response]]], \n",
    "    axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Transform validation data using same objects from training data. Note that we call |\n",
    "# only `transform` on test dataset (not fit_transform).                              |\n",
    "# ------------------------------------------------------------------------------------\n",
    "dfcategorical_validate = dfvalidate[categorical_vars]\n",
    "dfcontinuous_validate = dfvalidate[continuous_vars]\n",
    "\n",
    "validate_categorical_arr = categorical_imputer.transform(dfcategorical_validate[categorical_vars])\n",
    "validate_continuous_arr = continuous_imputer.transform(dfcontinuous_validate[continuous_vars])\n",
    "\n",
    "# One-hot encode categorical features.\n",
    "dfcategorical_validate = pd.DataFrame(\n",
    "    validate_categorical_arr, columns=categorical_vars\n",
    "    )\n",
    "\n",
    "dfcategorical_validate = pd.get_dummies(\n",
    "    dfcategorical_validate, columns=categorical_vars, drop_first=True\n",
    "    )\n",
    "\n",
    "# Scale continuous features to eliminate magnitude bias.\n",
    "dfcontinuous_validate = pd.DataFrame(\n",
    "    std_scaler.transform(validate_continuous_arr), columns=dfcontinuous_validate.columns\n",
    "    )\n",
    "\n",
    "# Recombine dfcategorical and dfcontinuous into single DataFrame with index.\n",
    "dfvalidate = pd.concat(\n",
    "    [dfvalidate[[\"id\"]], dfcategorical_validate, dfcontinuous_validate, dfvalidate[[response]]], \n",
    "    axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Transform test data using same objects from training data. Note that we call only  |\n",
    "# `transform` on test dataset (not fit_transform).                                   |\n",
    "# ------------------------------------------------------------------------------------\n",
    "dfcategorical_test = dftest[categorical_vars]\n",
    "dfcontinuous_test = dftest[continuous_vars]\n",
    "    \n",
    "test_categorical_arr = categorical_imputer.transform(dfcategorical_test[categorical_vars])\n",
    "test_continuous_arr = continuous_imputer.transform(dfcontinuous_test[continuous_vars])\n",
    "\n",
    "# One-hot encode categorical features.\n",
    "dfcategorical_test = pd.DataFrame(\n",
    "    test_categorical_arr, columns=categorical_vars\n",
    "    )\n",
    "\n",
    "dfcategorical_test = pd.get_dummies(\n",
    "    dfcategorical_test, columns=categorical_vars, drop_first=True\n",
    "    )\n",
    "\n",
    "# Scale continuous features to eliminate magnitude bias.\n",
    "dfcontinuous_test = pd.DataFrame(\n",
    "    std_scaler.transform(test_continuous_arr), columns=dfcontinuous_test.columns\n",
    "    )\n",
    "\n",
    "# Recombine dfcategorical and dfcontinuous into single DataFrame with index.\n",
    "dftest = pd.concat(\n",
    "    [dftest[[\"id\"]], dfcategorical_test, dfcontinuous_test, dftest[[response]]], \n",
    "    axis=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=False,\n",
      "                   intercept_scaling=1, l1_ratio=0.1, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='elasticnet',\n",
      "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression classifier to training data. Determine optimal\n",
    "# parameters using GridSearchCV.\n",
    "feature_columns = [i for i in dftrain.columns if i not in [\"id\", response]]\n",
    "X_train = dftrain[feature_columns]\n",
    "y_train = dftrain[response].values\n",
    "\n",
    "\n",
    "# Determine optimal parameters using GridSearchCV.\n",
    "lrc = linear_model.LogisticRegression()\n",
    "\n",
    "param_grid = [{\n",
    "    \"fit_intercept\":[True, False],\n",
    "    \"penalty\"      :[\"elasticnet\"],\n",
    "    \"solver\"       :[\"saga\"],\n",
    "    \"C\"            :[1/10000, 1/1000, 1/100, 1/10, 1, 10, 100, 1000, 10000],\n",
    "    \"l1_ratio\"     :np.arange(0, 1.1, .1)\n",
    "    }]\n",
    "\n",
    "# scoring can be one of [\"accuracy\", \"precision\", \"recall\", \"f1_macro\", \"roc_auc\"]\n",
    "grid_search = GridSearchCV(lrc, param_grid, cv=5, scoring=\"recall\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "lrc_params = grid_search.best_params_\n",
    "lrc_best = grid_search.best_estimator_\n",
    "print(lrc_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc_params = grid_search.best_params_\n",
    "clfbest = grid_search.best_estimator_\n",
    "clf_pred = clfbest.predict(Xtest)\n",
    "clf_prob = clfbest.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split explanatory variables from response, and convert\n",
    "# 1/2 response to 0/1 =>\n",
    "X = df.drop(['GENDER','ID'], axis=1)\n",
    "y = df['GENDER'].map(lambda x: 0 if x==2 else x).values\n",
    "\n",
    "# use `model_selection` in the latest release of scikit-learn =>\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                X, y, test_size=.33, random_state=16)\n",
    "\n",
    "# scale explanatory variables ================================================>\n",
    "sclr    = StandardScaler()\n",
    "X_train = sclr.fit_transform(X_train)\n",
    "X_test  = sclr.transform(X_test)\n",
    "\n",
    "# instantiate model ==========================================================>\n",
    "lr = LogisticRegression(C=1.0).fit(X_train, y_train)\n",
    "\n",
    "# get predictions (y_hat) and probabilities (p_hat) =>\n",
    "y_hat = lr.predict(X_test)\n",
    "p_hat = lr.predict_proba(X_test)[:,[1]]\n",
    "\n",
    "\n",
    "\n",
    "# evaluate logistic regression model =========================================>\n",
    "lr_score  = lr.score(X_test, y_test)\n",
    "cm        = confusion_matrix(actual_response, predicted_response)\n",
    "cr        = classification_report(y_test, lr_y_hat, target_names=['Male', 'Female'])\n",
    "auc_score = roc_auc_score(y_test, p_hat)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================>\n",
    "# Calling classifier's `decision_function` method to adjust the\n",
    "# discrimination threshold ===================================================>\n",
    "\n",
    "y_scores = lr.decision_function(X_test)\n",
    "\n",
    "# combine original classification with y_scores:\n",
    "sp = sorted(list(zip(y_scores.tolist(), y_hat.tolist())), key=lambda x: x[0])\n",
    "\n",
    "# set new thresholds =>\n",
    "new_threshold1 = 1.95\n",
    "new_predict1   = (y_scores>new_threshold1)*1\n",
    "\n",
    "new_threshold2 = 2.35\n",
    "new_predict2   = (y_scores>new_threshold2)*1\n",
    "\n",
    "new_threshold3 = 3.0\n",
    "new_predict3   = (y_scores>new_threshold3)*1\n",
    "\n",
    "\n",
    "# create a dict of updated predicitions based on updated threshold =>\n",
    "thresholds = {\n",
    "        '1.95':new_predict1,\n",
    "        '2.35':new_predict2,\n",
    "        '3.00':new_predict3\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
